{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3081fcbe-908b-4f9a-8c61-e04347b6856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "reviews = ['nice food',\n",
    "        'amazing restaurant',\n",
    "        'too good',\n",
    "        'just loved it!',\n",
    "        'will go again',\n",
    "        'horrible food',\n",
    "        'never go there',\n",
    "        'poor service',\n",
    "        'poor quality',\n",
    "        'needs improvement']\n",
    "\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fd3f7-88a8-4074-9554-b9e9442cffd9",
   "metadata": {},
   "source": [
    "\n",
    "The one_hot function in tensorflow.keras.preprocessing.text does word hashing (not the full one-hot encoding you might expect from NumPy).\n",
    "   It takes a string of text â†’ \"amazing restaurant\".\n",
    "   It splits it into words â†’ [\"amazing\", \"restaurant\"].\n",
    "   Each word is mapped to an integer index using a hashing function.\n",
    "   The integer will be between 1 and the given vocabulary size (n = 30 in your example).\n",
    "   The hashing is deterministic: same word â†’ same index every time.\n",
    "   Different words may collide (map to the same number), since itâ€™s hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115570f8-bf69-4977-aa3e-3872365336f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(\"amazing restaurant\",30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac06cc2b-1cf0-46e2-b249-f916d16d856c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23, 10],\n",
       " [28, 9],\n",
       " [12, 16],\n",
       " [10, 27, 17],\n",
       " [11, 17, 24],\n",
       " [21, 10],\n",
       " [11, 17, 3],\n",
       " [23, 12],\n",
       " [23, 20],\n",
       " [19, 3]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 30\n",
    "encoded_reviews = [one_hot(d, vocab_size) for d in reviews] # List Comprehension\n",
    "encoded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ac80ad-e2e9-4cbb-bed7-e62da8327b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23 10  0  0]\n",
      " [28  9  0  0]\n",
      " [12 16  0  0]\n",
      " [10 27 17  0]\n",
      " [11 17 24  0]\n",
      " [21 10  0  0]\n",
      " [11 17  3  0]\n",
      " [23 12  0  0]\n",
      " [23 20  0  0]\n",
      " [19  3  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# All the input texts has uneven size inputs -> So we do PADDING -> to make a maximum fixed size vector -> all embedded words has same vector length\n",
    "# By this , model works efficiently.\n",
    "max_length = 4\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "print(padded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12452466-6f36-4a9c-92bc-f75e831a22a6",
   "metadata": {},
   "source": [
    "Attributes explained:\n",
    "\n",
    "1. vocab_size\n",
    "\n",
    "Size of your vocabulary.\n",
    "\n",
    "In your case: 30.\n",
    "\n",
    "Meaning: embedding layer expects word indices from 1 â†’ 30 (Given vocab size).\n",
    "\n",
    "2. embeded_vector_size (also called output_dim)\n",
    "\n",
    "The size of the vector for each word.\n",
    "\n",
    "Example: if embeded_vector_size = 5, then each word index is mapped to a 5-dimensional vector like [0.12, -0.07, 0.55, 0.33, -0.9].\n",
    "\n",
    "You choose this size (common values: 50, 100, 300 depending on dataset size).\n",
    "\n",
    "Bigger size â†’ captures more semantic detail, but requires more computation.\n",
    "\n",
    "3. input_length\n",
    "\n",
    "Length of each input sequence (number of words in a review).\n",
    "\n",
    "You set this to max_length = 4.\n",
    "\n",
    "So every review is exactly 4 words long (after padding/truncating).\n",
    "\n",
    "ğŸ”¹ 2. Why do we pad sequences?\n",
    "\n",
    "Real reviews (sentences) have different lengths:\n",
    "\n",
    "\"Amazing food\" â†’ 2 words\n",
    "\n",
    "\"Service was great, loved it\" â†’ 5 words\n",
    "\n",
    "But neural networks need fixed-size inputs (like an image always has the same width Ã— height).\n",
    "Makes all reviews exactly max_length (here = 4).\n",
    "\n",
    "If shorter â†’ add 0s (padding).\n",
    "\n",
    "If longer â†’ truncate.\n",
    "\n",
    "ğŸ”¹ 3. Why give embedding size different from input length?\n",
    "\n",
    "This is a common confusion. Letâ€™s clarify:\n",
    "\n",
    "Input length (max_length) = number of words in each review.\n",
    "\n",
    "Embedding size (embeded_vector_size) = number of features used to represent each word.\n",
    "\n",
    "ğŸ‘‰ Example:\n",
    "\n",
    "A review: \"amazing restaurant service nice\" (4 words).\n",
    "\n",
    "After encoding: [3, 7, 12, 9].\n",
    "\n",
    "Embedding layer maps each index to a 5D vector (since embeded_vector_size = 5).\n",
    "\n",
    "ğŸ”¹ 4. Why not make embedding size = input length?\n",
    "\n",
    "Because they serve different purposes:\n",
    "\n",
    "Input length = how many words you process in a sentence.\n",
    "\n",
    "Embedding size = how detailed each word representation is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d669ec-d3bf-46f3-93d3-c2dae68df252",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_vector_size = 5\n",
    "\n",
    "# Now Keras is smart enough to infer the sequence input length automatically from your input, so you can safely remove input_length.\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_length,)))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embeded_vector_size, name=\"embedding\"))\n",
    "model.add(Flatten()) # to combiine all the embedded vectors to a single flatten vector, so that we can pass it to ANN network. \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d3a689-069a-4591-b6b4-ad4b96e5427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_reviews\n",
    "y = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d04308-88d7-4227-8adc-dd18f6c8a161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m5\u001b[0m)                â”‚             \u001b[38;5;34m150\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m21\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171</span> (684.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m171\u001b[0m (684.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171</span> (684.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m171\u001b[0m (684.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cf46858830>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(x, y, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f61b913-ce3d-46ae-8c73-730bb1143adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9000 - loss: 0.6438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8999999761581421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x,y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb37dc4-46ed-4afb-886b-bf5800b50afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00172095, -0.03296547,  0.03338961, -0.03135638, -0.04979312],\n",
       "        [-0.04114653,  0.04892534, -0.01560957,  0.00348396, -0.02617691],\n",
       "        [-0.0377836 , -0.02094356,  0.00520033,  0.02116619,  0.01842507],\n",
       "        [ 0.0888855 , -0.0740597 , -0.0238796 ,  0.03314437, -0.11607344],\n",
       "        [-0.01881489, -0.03655418,  0.04949501, -0.00769633, -0.04202037],\n",
       "        [ 0.00609331, -0.03501867,  0.0439705 , -0.00453931, -0.00630636],\n",
       "        [-0.02187084, -0.01523805, -0.04102244, -0.04566239, -0.0273971 ],\n",
       "        [-0.03322246,  0.0428693 ,  0.01778976, -0.01179652, -0.04652549],\n",
       "        [ 0.02847895,  0.00892083,  0.02931624, -0.01875533,  0.04594996],\n",
       "        [-0.04767699,  0.0342176 ,  0.0366229 , -0.07463325,  0.01019223],\n",
       "        [ 0.01329623, -0.00126175, -0.0109999 , -0.0159645 , -0.0084962 ],\n",
       "        [ 0.00247509,  0.0097402 ,  0.03881373, -0.03589834, -0.0371456 ],\n",
       "        [ 0.04881279, -0.09162681, -0.11176376, -0.06457805, -0.09377867],\n",
       "        [ 0.01448018,  0.04854338,  0.03360989,  0.03643483,  0.01628537],\n",
       "        [-0.00609816, -0.04401504,  0.00636418, -0.02626377,  0.04462478],\n",
       "        [-0.02673075, -0.02644367,  0.04563764, -0.04579708, -0.02878134],\n",
       "        [-0.05472041,  0.01397613,  0.00882718, -0.00416157,  0.05461086],\n",
       "        [-0.01442976,  0.00680855, -0.00406022, -0.02397306,  0.04636965],\n",
       "        [-0.005424  , -0.01062428, -0.03193184, -0.02118791,  0.01232922],\n",
       "        [-0.09628139,  0.0153749 ,  0.08395218,  0.07122223,  0.02054298],\n",
       "        [ 0.08707287, -0.00133255, -0.0416425 ,  0.00623085, -0.02892454],\n",
       "        [-0.01760481,  0.03439012,  0.06634402,  0.03574412,  0.0802266 ],\n",
       "        [-0.00159674,  0.02035907,  0.00743144,  0.03520024,  0.01440562],\n",
       "        [-0.03253042,  0.02383368,  0.00374524,  0.03987383, -0.00272966],\n",
       "        [-0.03090781,  0.08751535,  0.05163585,  0.05020698,  0.08981793],\n",
       "        [-0.04684592,  0.03976462, -0.03316253, -0.04095383, -0.01433967],\n",
       "        [ 0.03537465, -0.04056035,  0.01353301,  0.04410603,  0.01890225],\n",
       "        [-0.03078532,  0.092034  ,  0.01868562, -0.00244288,  0.05465098],\n",
       "        [ 0.05191595, -0.03156139, -0.05538976, -0.03349581, -0.09564536],\n",
       "        [ 0.00473347, -0.04061856, -0.00523277,  0.00655224,  0.01671015]],\n",
       "       dtype=float32),\n",
       " 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0] # extracts the embedding matrix from that list.\n",
    "weights, len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a0d4ae-2609-456b-96b7-481ab4ba496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01448018, 0.04854338, 0.03360989, 0.03643483, 0.01628537],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[13] # embedding vector of one-hot encoded word from the sentence = (13) index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b68b77-ba6a-48be-90f9-ca4a66cef69b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
